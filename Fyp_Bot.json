{"id":"2b29ed43-96c4-4942-a2c3-d2a86f908b3d","data":{"nodes":[{"id":"TextInput-zvrMz","type":"genericNode","position":{"x":-50.459113520552194,"y":53.68229431500558},"data":{"type":"TextInput","node":{"template":{"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"hi\n","fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Value","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Text or Record to be passed as input.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Interaction Panel.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get text inputs from the Interaction Panel.","icon":"type","base_classes":["object","str","Text"],"display_name":"Name","documentation":"","custom_fields":{"input_value":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"TextInput-zvrMz"},"selected":false,"width":384,"height":289},{"id":"ChatInput-JY2A0","type":"genericNode","position":{"x":686.0701702862268,"y":56.082294315005555},"data":{"type":"ChatInput","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Record\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Interaction Panel.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"input_types\": [],\n            \"display_name\": \"Message\",\n            \"multiline\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n    ) -> Union[Text, Record]:\n        return super().build_no_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Message","advanced":false,"input_types":[],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"value":"hihow was the proggram did offer by focs"},"return_record":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_record","display_name":"Return Record","advanced":true,"dynamic":false,"info":"Return the message as a record containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get chat inputs from the Interaction Panel.","icon":"ChatInput","base_classes":["object","Record","str","Text"],"display_name":"Chat Input","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"return_record":null},"output_types":["Text","Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatInput-JY2A0"},"selected":false,"width":384,"height":375},{"id":"Prompt-qT5rm","type":"genericNode","position":{"x":1356.0701702862268,"y":-32.52935737488278},"data":{"type":"Prompt","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.prompts import PromptTemplate\n\nfrom langflow.field_typing import Prompt, TemplateField, Text\nfrom langflow.interface.custom.custom_component import CustomComponent\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from langflow.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"prompt","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"Hey, answer the users question based on the following context:\n\nThe context is this: {context}\n\nAnd this is the message history: {history}\n\nThe users question is this: {question}\n","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent","context":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"context","display_name":"context","advanced":false,"input_types":["Document","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"history":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"history","display_name":"history","advanced":false,"input_types":["Document","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"question":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"question","display_name":"question","advanced":false,"input_types":["Document","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["object","str","Text"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["context","history","question"]},"output_types":["Text"],"full_path":null,"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"error":null},"id":"Prompt-qT5rm","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":true,"width":384,"height":571,"dragging":false,"positionAbsolute":{"x":1356.0701702862268,"y":-32.52935737488278}},{"id":"MemoryComponent-k8Jsz","type":"genericNode","position":{"x":682.2580022308748,"y":511.7068785427141},"data":{"type":"MemoryComponent","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.field_typing import Text\nfrom langflow.helpers.record import records_to_text\nfrom langflow.interface.custom.custom_component import CustomComponent\nfrom langflow.memory import get_messages\n\n\nclass MemoryComponent(CustomComponent):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages given a specific Session ID.\"\n    beta: bool = True\n    icon = \"history\"\n\n    def build_config(self):\n        return {\n            \"sender\": {\n                \"options\": [\"Machine\", \"User\", \"Machine and User\"],\n                \"display_name\": \"Sender Type\",\n            },\n            \"sender_name\": {\"display_name\": \"Sender Name\", \"advanced\": True},\n            \"n_messages\": {\n                \"display_name\": \"Number of Messages\",\n                \"info\": \"Number of messages to retrieve.\",\n            },\n            \"session_id\": {\n                \"display_name\": \"Session ID\",\n                \"info\": \"Session ID of the chat history.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"order\": {\n                \"options\": [\"Ascending\", \"Descending\"],\n                \"display_name\": \"Order\",\n                \"info\": \"Order of the messages.\",\n                \"advanced\": True,\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine and User\",\n        sender_name: Optional[str] = None,\n        session_id: Optional[str] = None,\n        n_messages: int = 5,\n        order: Optional[str] = \"Descending\",\n        record_template: Optional[str] = \"{sender_name}: {text}\",\n    ) -> Text:\n        order = \"DESC\" if order == \"Descending\" else \"ASC\"\n        if sender == \"Machine and User\":\n            sender = None\n        messages = get_messages(\n            sender=sender,\n            sender_name=sender_name,\n            session_id=session_id,\n            limit=n_messages,\n            order=order,\n        )\n        messages_str = records_to_text(template=record_template or \"\", records=messages)\n        self.status = messages_str\n        return messages_str\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"n_messages":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":5,"fileTypes":[],"file_path":"","password":false,"name":"n_messages","display_name":"Number of Messages","advanced":false,"dynamic":false,"info":"Number of messages to retrieve.","load_from_db":false,"title_case":false},"order":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Descending","fileTypes":[],"file_path":"","password":false,"options":["Ascending","Descending"],"name":"order","display_name":"Order","advanced":true,"dynamic":false,"info":"Order of the messages.","load_from_db":false,"title_case":false,"input_types":["Text"]},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"{sender_name}: {text}","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine and User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User","Machine and User"],"name":"sender","display_name":"Sender Type","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":false,"input_types":["Text"],"dynamic":false,"info":"Session ID of the chat history.","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Retrieves stored chat messages given a specific Session ID.","icon":"history","base_classes":["object","str","Text"],"display_name":"Chat Memory","documentation":"","custom_fields":{"sender":null,"sender_name":null,"session_id":null,"n_messages":null,"order":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":true},"id":"MemoryComponent-k8Jsz"},"selected":false,"width":384,"height":489},{"id":"OllamaModel-Sso5e","type":"genericNode","position":{"x":1889.4382214229006,"y":133.18124999999998},"data":{"type":"OllamaModel","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"metadata":{"type":"Dict[str, Any]","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata","display_name":"Metadata","advanced":true,"dynamic":false,"info":"Metadata to add to the run trace.","load_from_db":false,"title_case":false},"stop":{"type":"list","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"stop","display_name":"Stop Tokens","advanced":true,"dynamic":false,"info":"List of tokens to signal the model to stop generating text.","load_from_db":false,"title_case":false},"tags":{"type":"list","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"tags","display_name":"Tags","advanced":true,"dynamic":false,"info":"Tags to add to the run trace.","load_from_db":false,"title_case":false},"base_url":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"base_url","display_name":"Base URL","advanced":false,"dynamic":false,"info":"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"http://localhost:11434"},"cache":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"cache","display_name":"Cache","advanced":true,"dynamic":false,"info":"Enable or disable caching.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Any, Dict, List, Optional\n\n# from langchain_community.chat_models import ChatOllama\nfrom langchain_community.chat_models import ChatOllama\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\n\n# from langchain.chat_models import ChatOllama\nfrom langflow.field_typing import Text\n\n# whe When a callback component is added to Langflow, the comment must be uncommented.\n# from langchain.callbacks.manager import CallbackManager\n\n\nclass ChatOllamaComponent(LCModelComponent):\n    display_name = \"Ollama\"\n    description = \"Generate text using Ollama Local LLMs.\"\n    icon = \"Ollama\"\n\n    field_order = [\n        \"base_url\",\n        \"model\",\n        \"temperature\",\n        \"cache\",\n        \"callback_manager\",\n        \"callbacks\",\n        \"format\",\n        \"metadata\",\n        \"mirostat\",\n        \"mirostat_eta\",\n        \"mirostat_tau\",\n        \"num_ctx\",\n        \"num_gpu\",\n        \"num_thread\",\n        \"repeat_last_n\",\n        \"repeat_penalty\",\n        \"tfs_z\",\n        \"timeout\",\n        \"top_k\",\n        \"top_p\",\n        \"verbose\",\n        \"tags\",\n        \"stop\",\n        \"system\",\n        \"template\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self) -> dict:\n        return {\n            \"base_url\": {\n                \"display_name\": \"Base URL\",\n                \"info\": \"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n                \"advanced\": True,\n            },\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": \"llama2\",\n                \"info\": \"Refer to https://ollama.ai/library for more models.\",\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"value\": 0.8,\n                \"info\": \"Controls the creativity of model responses.\",\n            },\n            \"cache\": {\n                \"display_name\": \"Cache\",\n                \"field_type\": \"bool\",\n                \"info\": \"Enable or disable caching.\",\n                \"advanced\": True,\n                \"value\": False,\n            },\n            ### When a callback component is added to Langflow, the comment must be uncommented. ###\n            # \"callback_manager\": {\n            #     \"display_name\": \"Callback Manager\",\n            #     \"info\": \"Optional callback manager for additional functionality.\",\n            #     \"advanced\": True,\n            # },\n            # \"callbacks\": {\n            #     \"display_name\": \"Callbacks\",\n            #     \"info\": \"Callbacks to execute during model runtime.\",\n            #     \"advanced\": True,\n            # },\n            ########################################################################################\n            \"format\": {\n                \"display_name\": \"Format\",\n                \"field_type\": \"str\",\n                \"info\": \"Specify the format of the output (e.g., json).\",\n                \"advanced\": True,\n            },\n            \"metadata\": {\n                \"display_name\": \"Metadata\",\n                \"info\": \"Metadata to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"mirostat\": {\n                \"display_name\": \"Mirostat\",\n                \"options\": [\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n                \"info\": \"Enable/disable Mirostat sampling for controlling perplexity.\",\n                \"value\": \"Disabled\",\n                \"advanced\": True,\n            },\n            \"mirostat_eta\": {\n                \"display_name\": \"Mirostat Eta\",\n                \"field_type\": \"float\",\n                \"info\": \"Learning rate for Mirostat algorithm. (Default: 0.1)\",\n                \"advanced\": True,\n            },\n            \"mirostat_tau\": {\n                \"display_name\": \"Mirostat Tau\",\n                \"field_type\": \"float\",\n                \"info\": \"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\n                \"advanced\": True,\n            },\n            \"num_ctx\": {\n                \"display_name\": \"Context Window Size\",\n                \"field_type\": \"int\",\n                \"info\": \"Size of the context window for generating tokens. (Default: 2048)\",\n                \"advanced\": True,\n            },\n            \"num_gpu\": {\n                \"display_name\": \"Number of GPUs\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\n                \"advanced\": True,\n            },\n            \"num_thread\": {\n                \"display_name\": \"Number of Threads\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of threads to use during computation. (Default: detected for optimal performance)\",\n                \"advanced\": True,\n            },\n            \"repeat_last_n\": {\n                \"display_name\": \"Repeat Last N\",\n                \"field_type\": \"int\",\n                \"info\": \"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\n                \"advanced\": True,\n            },\n            \"repeat_penalty\": {\n                \"display_name\": \"Repeat Penalty\",\n                \"field_type\": \"float\",\n                \"info\": \"Penalty for repetitions in generated text. (Default: 1.1)\",\n                \"advanced\": True,\n            },\n            \"tfs_z\": {\n                \"display_name\": \"TFS Z\",\n                \"field_type\": \"float\",\n                \"info\": \"Tail free sampling value. (Default: 1)\",\n                \"advanced\": True,\n            },\n            \"timeout\": {\n                \"display_name\": \"Timeout\",\n                \"field_type\": \"int\",\n                \"info\": \"Timeout for the request stream.\",\n                \"advanced\": True,\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"field_type\": \"int\",\n                \"info\": \"Limits token selection to top K. (Default: 40)\",\n                \"advanced\": True,\n            },\n            \"top_p\": {\n                \"display_name\": \"Top P\",\n                \"field_type\": \"float\",\n                \"info\": \"Works together with top-k. (Default: 0.9)\",\n                \"advanced\": True,\n            },\n            \"verbose\": {\n                \"display_name\": \"Verbose\",\n                \"field_type\": \"bool\",\n                \"info\": \"Whether to print out response text.\",\n            },\n            \"tags\": {\n                \"display_name\": \"Tags\",\n                \"field_type\": \"list\",\n                \"info\": \"Tags to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"stop\": {\n                \"display_name\": \"Stop Tokens\",\n                \"field_type\": \"list\",\n                \"info\": \"List of tokens to signal the model to stop generating text.\",\n                \"advanced\": True,\n            },\n            \"system\": {\n                \"display_name\": \"System\",\n                \"field_type\": \"str\",\n                \"info\": \"System to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"template\": {\n                \"display_name\": \"Template\",\n                \"field_type\": \"str\",\n                \"info\": \"Template to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"input_value\": {\"display_name\": \"Input\"},\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        base_url: Optional[str],\n        model: str,\n        input_value: Text,\n        mirostat: Optional[str],\n        mirostat_eta: Optional[float] = None,\n        mirostat_tau: Optional[float] = None,\n        ### When a callback component is added to Langflow, the comment must be uncommented.###\n        # callback_manager: Optional[CallbackManager] = None,\n        # callbacks: Optional[List[Callbacks]] = None,\n        #######################################################################################\n        repeat_last_n: Optional[int] = None,\n        verbose: Optional[bool] = None,\n        cache: Optional[bool] = None,\n        num_ctx: Optional[int] = None,\n        num_gpu: Optional[int] = None,\n        format: Optional[str] = None,\n        metadata: Optional[Dict[str, Any]] = None,\n        num_thread: Optional[int] = None,\n        repeat_penalty: Optional[float] = None,\n        stop: Optional[List[str]] = None,\n        system: Optional[str] = None,\n        tags: Optional[List[str]] = None,\n        temperature: Optional[float] = None,\n        template: Optional[str] = None,\n        tfs_z: Optional[float] = None,\n        timeout: Optional[int] = None,\n        top_k: Optional[int] = None,\n        top_p: Optional[int] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not base_url:\n            base_url = \"http://localhost:11434\"\n\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n\n        # Mapping system settings to their corresponding values\n        llm_params = {\n            \"base_url\": base_url,\n            \"cache\": cache,\n            \"model\": model,\n            \"mirostat\": mirostat_value,\n            \"format\": format,\n            \"metadata\": metadata,\n            \"tags\": tags,\n            ## When a callback component is added to Langflow, the comment must be uncommented.##\n            # \"callback_manager\": callback_manager,\n            # \"callbacks\": callbacks,\n            #####################################################################################\n            \"mirostat_eta\": mirostat_eta,\n            \"mirostat_tau\": mirostat_tau,\n            \"num_ctx\": num_ctx,\n            \"num_gpu\": num_gpu,\n            \"num_thread\": num_thread,\n            \"repeat_last_n\": repeat_last_n,\n            \"repeat_penalty\": repeat_penalty,\n            \"temperature\": temperature,\n            \"stop\": stop,\n            \"system\": system,\n            \"template\": template,\n            \"tfs_z\": tfs_z,\n            \"timeout\": timeout,\n            \"top_k\": top_k,\n            \"top_p\": top_p,\n            \"verbose\": verbose,\n        }\n\n        # None Value remove\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\n\n        try:\n            output = ChatOllama(**llm_params)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not initialize Ollama LLM.\") from e\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"format":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"format","display_name":"Format","advanced":true,"dynamic":false,"info":"Specify the format of the output (e.g., json).","load_from_db":false,"title_case":false,"input_types":["Text"]},"mirostat":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Disabled","fileTypes":[],"file_path":"","password":false,"options":["Disabled","Mirostat","Mirostat 2.0"],"name":"mirostat","display_name":"Mirostat","advanced":true,"dynamic":false,"info":"Enable/disable Mirostat sampling for controlling perplexity.","load_from_db":false,"title_case":false,"input_types":["Text"]},"mirostat_eta":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"mirostat_eta","display_name":"Mirostat Eta","advanced":true,"dynamic":false,"info":"Learning rate for Mirostat algorithm. (Default: 0.1)","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"mirostat_tau":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"mirostat_tau","display_name":"Mirostat Tau","advanced":true,"dynamic":false,"info":"Controls the balance between coherence and diversity of the output. (Default: 5.0)","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"model":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":"llama2:7b","fileTypes":[],"file_path":"","password":false,"name":"model","display_name":"Model Name","advanced":false,"dynamic":false,"info":"Refer to https://ollama.ai/library for more models.","load_from_db":false,"title_case":false,"input_types":["Text"]},"num_ctx":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_ctx","display_name":"Context Window Size","advanced":true,"dynamic":false,"info":"Size of the context window for generating tokens. (Default: 2048)","load_from_db":false,"title_case":false},"num_gpu":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_gpu","display_name":"Number of GPUs","advanced":true,"dynamic":false,"info":"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)","load_from_db":false,"title_case":false},"num_thread":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_thread","display_name":"Number of Threads","advanced":true,"dynamic":false,"info":"Number of threads to use during computation. (Default: detected for optimal performance)","load_from_db":false,"title_case":false},"repeat_last_n":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"repeat_last_n","display_name":"Repeat Last N","advanced":true,"dynamic":false,"info":"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)","load_from_db":false,"title_case":false},"repeat_penalty":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"repeat_penalty","display_name":"Repeat Penalty","advanced":true,"dynamic":false,"info":"Penalty for repetitions in generated text. (Default: 1.1)","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":false,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"system":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system","display_name":"System","advanced":true,"dynamic":false,"info":"System to use for generating text.","load_from_db":false,"title_case":false,"input_types":["Text"]},"system_message":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"0.2","fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"Controls the creativity of model responses.","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":true,"dynamic":false,"info":"Template to use for generating text.","load_from_db":false,"title_case":false,"input_types":["Text"]},"tfs_z":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"tfs_z","display_name":"TFS Z","advanced":true,"dynamic":false,"info":"Tail free sampling value. (Default: 1)","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"timeout":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"timeout","display_name":"Timeout","advanced":true,"dynamic":false,"info":"Timeout for the request stream.","load_from_db":false,"title_case":false},"top_k":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"top_k","display_name":"Top K","advanced":true,"dynamic":false,"info":"Limits token selection to top K. (Default: 40)","load_from_db":false,"title_case":false},"top_p":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"top_p","display_name":"Top P","advanced":true,"dynamic":false,"info":"Works together with top-k. (Default: 0.9)","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"verbose":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"verbose","display_name":"Verbose","advanced":false,"dynamic":false,"info":"Whether to print out response text.","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generate text using Ollama Local LLMs.","icon":"Ollama","base_classes":["object","str","Text"],"display_name":"Ollama","documentation":"","custom_fields":{"base_url":null,"model":null,"input_value":null,"mirostat":null,"mirostat_eta":null,"mirostat_tau":null,"repeat_last_n":null,"verbose":null,"cache":null,"num_ctx":null,"num_gpu":null,"format":null,"metadata":null,"num_thread":null,"repeat_penalty":null,"stop":null,"system":null,"tags":null,"temperature":null,"template":null,"tfs_z":null,"timeout":null,"top_k":null,"top_p":null,"stream":null,"system_message":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["base_url","model","temperature","cache","callback_manager","callbacks","format","metadata","mirostat","mirostat_eta","mirostat_tau","num_ctx","num_gpu","num_thread","repeat_last_n","repeat_penalty","tfs_z","timeout","top_k","top_p","verbose","tags","stop","system","template","input_value","system_message","stream"],"beta":false},"id":"OllamaModel-Sso5e"},"selected":false,"width":384,"height":715,"positionAbsolute":{"x":1889.4382214229006,"y":133.18124999999998},"dragging":false},{"id":"ChatOutput-2WjKE","type":"genericNode","position":{"x":2540.007625262494,"y":103.9383516600125},"data":{"type":"ChatOutput","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Record\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Interaction Panel.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n        record_template: Optional[str] = \"{text}\",\n    ) -> Union[Text, Record]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n            record_template=record_template or \"\",\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Message","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"{text}","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"In case of Message being a Record, this template will be used to convert it to text.","load_from_db":false,"title_case":false,"input_types":["Text"]},"return_record":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_record","display_name":"Return Record","advanced":true,"dynamic":false,"info":"Return the message as a record containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"AI","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a chat message in the Interaction Panel.","icon":"ChatOutput","base_classes":["object","Record","str","Text"],"display_name":"Chat Output","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"return_record":null,"record_template":null},"output_types":["Text","Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatOutput-2WjKE"},"selected":false,"width":384,"height":383},{"id":"AstraDB-wA82a","type":"genericNode","position":{"x":2413.360750254482,"y":1271.9661796875155},"data":{"type":"AstraDB","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"Embedding to use","load_from_db":false,"title_case":false},"inputs":{"type":"Record","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","display_name":"Inputs","advanced":false,"dynamic":false,"info":"Optional list of records to be processed and stored in the vector store.","load_from_db":false,"title_case":false},"api_endpoint":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"api_endpoint","display_name":"API Endpoint","advanced":false,"dynamic":false,"info":"API endpoint URL for the Astra DB service.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"https://bb20db55-ad46-4cc0-bde5-349ac80533a3-us-east1.apps.astra.datastax.com"},"batch_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"batch_size","display_name":"Batch Size","advanced":true,"dynamic":false,"info":"Optional number of records to process in a single batch.","load_from_db":false,"title_case":false},"bulk_delete_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_delete_concurrency","display_name":"Bulk Delete Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk delete operations.","load_from_db":false,"title_case":false},"bulk_insert_batch_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_insert_batch_concurrency","display_name":"Bulk Insert Batch Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations.","load_from_db":false,"title_case":false},"bulk_insert_overwrite_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_insert_overwrite_concurrency","display_name":"Bulk Insert Overwrite Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations that overwrite existing records.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional\n\nfrom langchain_astradb import AstraDBVectorStore\nfrom langchain_astradb.utils.astradb import SetupMode\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Embeddings, VectorStore\nfrom langflow.schema import Record\n\n\nclass AstraDBVectorStoreComponent(CustomComponent):\n    display_name = \"Astra DB\"\n    description = \"Builds or loads an Astra DB Vector Store.\"\n    icon = \"AstraDB\"\n    field_order = [\"token\", \"api_endpoint\", \"collection_name\", \"inputs\", \"embedding\"]\n\n    def build_config(self):\n        return {\n            \"inputs\": {\n                \"display_name\": \"Inputs\",\n                \"info\": \"Optional list of records to be processed and stored in the vector store.\",\n            },\n            \"embedding\": {\"display_name\": \"Embedding\", \"info\": \"Embedding to use\"},\n            \"collection_name\": {\n                \"display_name\": \"Collection Name\",\n                \"info\": \"The name of the collection within Astra DB where the vectors will be stored.\",\n            },\n            \"token\": {\n                \"display_name\": \"Token\",\n                \"info\": \"Authentication token for accessing Astra DB.\",\n                \"password\": True,\n            },\n            \"api_endpoint\": {\n                \"display_name\": \"API Endpoint\",\n                \"info\": \"API endpoint URL for the Astra DB service.\",\n            },\n            \"namespace\": {\n                \"display_name\": \"Namespace\",\n                \"info\": \"Optional namespace within Astra DB to use for the collection.\",\n                \"advanced\": True,\n            },\n            \"metric\": {\n                \"display_name\": \"Metric\",\n                \"info\": \"Optional distance metric for vector comparisons in the vector store.\",\n                \"advanced\": True,\n            },\n            \"batch_size\": {\n                \"display_name\": \"Batch Size\",\n                \"info\": \"Optional number of records to process in a single batch.\",\n                \"advanced\": True,\n            },\n            \"bulk_insert_batch_concurrency\": {\n                \"display_name\": \"Bulk Insert Batch Concurrency\",\n                \"info\": \"Optional concurrency level for bulk insert operations.\",\n                \"advanced\": True,\n            },\n            \"bulk_insert_overwrite_concurrency\": {\n                \"display_name\": \"Bulk Insert Overwrite Concurrency\",\n                \"info\": \"Optional concurrency level for bulk insert operations that overwrite existing records.\",\n                \"advanced\": True,\n            },\n            \"bulk_delete_concurrency\": {\n                \"display_name\": \"Bulk Delete Concurrency\",\n                \"info\": \"Optional concurrency level for bulk delete operations.\",\n                \"advanced\": True,\n            },\n            \"setup_mode\": {\n                \"display_name\": \"Setup Mode\",\n                \"info\": \"Configuration mode for setting up the vector store, with options like “Sync”, “Async”, or “Off”.\",\n                \"options\": [\"Sync\", \"Async\", \"Off\"],\n                \"advanced\": True,\n            },\n            \"pre_delete_collection\": {\n                \"display_name\": \"Pre Delete Collection\",\n                \"info\": \"Boolean flag to determine whether to delete the collection before creating a new one.\",\n                \"advanced\": True,\n            },\n            \"metadata_indexing_include\": {\n                \"display_name\": \"Metadata Indexing Include\",\n                \"info\": \"Optional list of metadata fields to include in the indexing.\",\n                \"advanced\": True,\n            },\n            \"metadata_indexing_exclude\": {\n                \"display_name\": \"Metadata Indexing Exclude\",\n                \"info\": \"Optional list of metadata fields to exclude from the indexing.\",\n                \"advanced\": True,\n            },\n            \"collection_indexing_policy\": {\n                \"display_name\": \"Collection Indexing Policy\",\n                \"info\": \"Optional dictionary defining the indexing policy for the collection.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        embedding: Embeddings,\n        token: str,\n        api_endpoint: str,\n        collection_name: str,\n        inputs: Optional[List[Record]] = None,\n        namespace: Optional[str] = None,\n        metric: Optional[str] = None,\n        batch_size: Optional[int] = None,\n        bulk_insert_batch_concurrency: Optional[int] = None,\n        bulk_insert_overwrite_concurrency: Optional[int] = None,\n        bulk_delete_concurrency: Optional[int] = None,\n        setup_mode: str = \"Sync\",\n        pre_delete_collection: bool = False,\n        metadata_indexing_include: Optional[List[str]] = None,\n        metadata_indexing_exclude: Optional[List[str]] = None,\n        collection_indexing_policy: Optional[dict] = None,\n    ) -> VectorStore:\n        try:\n            setup_mode_value = SetupMode[setup_mode.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid setup mode: {setup_mode}\")\n        if inputs:\n            documents = [_input.to_lc_document() for _input in inputs]\n\n            vector_store = AstraDBVectorStore.from_documents(\n                documents=documents,\n                embedding=embedding,\n                collection_name=collection_name,\n                token=token,\n                api_endpoint=api_endpoint,\n                namespace=namespace,\n                metric=metric,\n                batch_size=batch_size,\n                bulk_insert_batch_concurrency=bulk_insert_batch_concurrency,\n                bulk_insert_overwrite_concurrency=bulk_insert_overwrite_concurrency,\n                bulk_delete_concurrency=bulk_delete_concurrency,\n                setup_mode=setup_mode_value,\n                pre_delete_collection=pre_delete_collection,\n                metadata_indexing_include=metadata_indexing_include,\n                metadata_indexing_exclude=metadata_indexing_exclude,\n                collection_indexing_policy=collection_indexing_policy,\n            )\n        else:\n            vector_store = AstraDBVectorStore(\n                embedding=embedding,\n                collection_name=collection_name,\n                token=token,\n                api_endpoint=api_endpoint,\n                namespace=namespace,\n                metric=metric,\n                batch_size=batch_size,\n                bulk_insert_batch_concurrency=bulk_insert_batch_concurrency,\n                bulk_insert_overwrite_concurrency=bulk_insert_overwrite_concurrency,\n                bulk_delete_concurrency=bulk_delete_concurrency,\n                setup_mode=setup_mode_value,\n                pre_delete_collection=pre_delete_collection,\n                metadata_indexing_include=metadata_indexing_include,\n                metadata_indexing_exclude=metadata_indexing_exclude,\n                collection_indexing_policy=collection_indexing_policy,\n            )\n\n        return vector_store\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_indexing_policy":{"type":"dict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_indexing_policy","display_name":"Collection Indexing Policy","advanced":true,"dynamic":false,"info":"Optional dictionary defining the indexing policy for the collection.","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"The name of the collection within Astra DB where the vectors will be stored.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"pdf"},"metadata_indexing_exclude":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata_indexing_exclude","display_name":"Metadata Indexing Exclude","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to exclude from the indexing.","load_from_db":false,"title_case":false,"input_types":["Text"]},"metadata_indexing_include":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata_indexing_include","display_name":"Metadata Indexing Include","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to include in the indexing.","load_from_db":false,"title_case":false,"input_types":["Text"]},"metric":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metric","display_name":"Metric","advanced":true,"dynamic":false,"info":"Optional distance metric for vector comparisons in the vector store.","load_from_db":false,"title_case":false,"input_types":["Text"]},"namespace":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"namespace","display_name":"Namespace","advanced":true,"dynamic":false,"info":"Optional namespace within Astra DB to use for the collection.","load_from_db":false,"title_case":false,"input_types":["Text"]},"pre_delete_collection":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"pre_delete_collection","display_name":"Pre Delete Collection","advanced":true,"dynamic":false,"info":"Boolean flag to determine whether to delete the collection before creating a new one.","load_from_db":false,"title_case":false},"setup_mode":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Sync","fileTypes":[],"file_path":"","password":false,"options":["Sync","Async","Off"],"name":"setup_mode","display_name":"Setup Mode","advanced":true,"dynamic":false,"info":"Configuration mode for setting up the vector store, with options like “Sync”, “Async”, or “Off”.","load_from_db":false,"title_case":false,"input_types":["Text"]},"token":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"token","display_name":"Token","advanced":false,"dynamic":false,"info":"Authentication token for accessing Astra DB.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"AstraCS:vAMZkfwNjndvIYjaRcexnWpQ:4e52e6a1e8f83086c8108f248dfc58295345384a2cddcb734690aa433b88a98f"},"_type":"CustomComponent"},"description":"Builds or loads an Astra DB Vector Store.","icon":"AstraDB","base_classes":["VectorStore"],"display_name":"Astra DB","documentation":"","custom_fields":{"embedding":null,"token":null,"api_endpoint":null,"collection_name":null,"inputs":null,"namespace":null,"metric":null,"batch_size":null,"bulk_insert_batch_concurrency":null,"bulk_insert_overwrite_concurrency":null,"bulk_delete_concurrency":null,"setup_mode":null,"pre_delete_collection":null,"metadata_indexing_include":null,"metadata_indexing_exclude":null,"collection_indexing_policy":null},"output_types":["VectorStore"],"field_formatters":{},"frozen":false,"field_order":["token","api_endpoint","collection_name","inputs","embedding"],"beta":false},"id":"AstraDB-wA82a"},"selected":false,"width":384,"height":573,"dragging":false},{"id":"OllamaEmbeddings-mv0aG","type":"genericNode","position":{"x":749.7309233389592,"y":2121.181442681803},"data":{"type":"OllamaEmbeddings","node":{"template":{"base_url":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"http://localhost:11434","fileTypes":[],"file_path":"","password":false,"name":"base_url","display_name":"Ollama Base URL","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain.embeddings.base import Embeddings\nfrom langchain_community.embeddings import OllamaEmbeddings\n\nfrom langflow.interface.custom.custom_component import CustomComponent\n\n\nclass OllamaEmbeddingsComponent(CustomComponent):\n    display_name: str = \"Ollama Embeddings\"\n    description: str = \"Generate embeddings using Ollama models.\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n\n    def build_config(self):\n        return {\n            \"model\": {\n                \"display_name\": \"Ollama Model\",\n            },\n            \"base_url\": {\"display_name\": \"Ollama Base URL\"},\n            \"temperature\": {\"display_name\": \"Model Temperature\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        model: str = \"llama2\",\n        base_url: str = \"http://localhost:11434\",\n        temperature: Optional[float] = None,\n    ) -> Embeddings:\n        try:\n            output = OllamaEmbeddings(model=model, base_url=base_url, temperature=temperature)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not connect to Ollama API.\") from e\n        return output\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"model":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"llama2:7b","fileTypes":[],"file_path":"","password":false,"name":"model","display_name":"Ollama Model","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Model Temperature","advanced":false,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false,"value":"0.2"},"_type":"CustomComponent"},"description":"Generate embeddings using Ollama models.","base_classes":["Embeddings"],"display_name":"Ollama Embeddings","documentation":"https://python.langchain.com/docs/integrations/text_embedding/ollama","custom_fields":{"model":null,"base_url":null,"temperature":null},"output_types":["Embeddings"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"OllamaEmbeddings-mv0aG"},"selected":false,"width":384,"height":469,"positionAbsolute":{"x":749.7309233389592,"y":2121.181442681803},"dragging":false},{"id":"File-NZc5f","type":"genericNode","position":{"x":-222.00000000000006,"y":1195.1575089437883},"data":{"type":"File","node":{"template":{"path":{"type":"file","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx"],"file_path":"2b29ed43-96c4-4942-a2c3-d2a86f908b3d\\FacultyofComputingandInformationTechnology2024.pdf","password":false,"name":"path","display_name":"Path","advanced":false,"dynamic":false,"info":"Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from pathlib import Path\nfrom typing import Any, Dict\n\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_record\nfrom langflow.interface.custom.custom_component import CustomComponent\nfrom langflow.schema import Record\n\n\nclass FileComponent(CustomComponent):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n\n    def build_config(self) -> Dict[str, Any]:\n        return {\n            \"path\": {\n                \"display_name\": \"Path\",\n                \"field_type\": \"file\",\n                \"file_types\": TEXT_FILE_TYPES,\n                \"info\": f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n            },\n            \"silent_errors\": {\n                \"display_name\": \"Silent Errors\",\n                \"advanced\": True,\n                \"info\": \"If true, errors will not raise an exception.\",\n            },\n        }\n\n    def load_file(self, path: str, silent_errors: bool = False) -> Record:\n        resolved_path = self.resolve_path(path)\n        path_obj = Path(resolved_path)\n        extension = path_obj.suffix[1:].lower()\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n        record = parse_text_file_to_record(resolved_path, silent_errors)\n        self.status = record if record else \"No data\"\n        return record or Record()\n\n    def build(\n        self,\n        path: str,\n        silent_errors: bool = False,\n    ) -> Record:\n        record = self.load_file(path, silent_errors)\n        self.status = record\n        return record\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"silent_errors":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"silent_errors","display_name":"Silent Errors","advanced":true,"dynamic":false,"info":"If true, errors will not raise an exception.","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"A generic file loader.","icon":"file-text","base_classes":["Record"],"display_name":"File","documentation":"","custom_fields":{"path":null,"silent_errors":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"File-NZc5f"},"selected":false,"width":384,"height":281,"dragging":false},{"id":"SplitText-aRYow","type":"genericNode","position":{"x":310.9353499759499,"y":1096.4617337288182},"data":{"type":"SplitText","node":{"template":{"inputs":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","display_name":"Inputs","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Texts to split.","load_from_db":false,"title_case":false},"chunk_overlap":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":200,"fileTypes":[],"file_path":"","password":false,"name":"chunk_overlap","display_name":"Chunk Overlap","advanced":false,"dynamic":false,"info":"The amount of character overlap between chunks.","load_from_db":false,"title_case":false},"chunk_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1000,"fileTypes":[],"file_path":"","password":false,"name":"chunk_size","display_name":"Max Chunk Size","advanced":false,"dynamic":false,"info":"The maximum length (in number of characters) of each chunk.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\nfrom langchain_core.documents import Document\n\nfrom langflow.field_typing import Text\nfrom langflow.interface.custom.custom_component import CustomComponent\nfrom langflow.schema import Record\nfrom langflow.utils.util import unescape_string\n\n\nclass SplitTextComponent(CustomComponent):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks of a specified length.\"\n\n    def build_config(self):\n        return {\n            \"inputs\": {\n                \"display_name\": \"Inputs\",\n                \"info\": \"Texts to split.\",\n                \"input_types\": [\"Record\", \"Text\"],\n            },\n            \"separators\": {\n                \"display_name\": \"Separators\",\n                \"info\": 'The characters to split on. Defaults to [\" \"].',\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\n                \"display_name\": \"Max Chunk Size\",\n                \"info\": \"The maximum length (in number of characters) of each chunk.\",\n                \"field_type\": \"int\",\n                \"value\": 1000,\n            },\n            \"chunk_overlap\": {\n                \"display_name\": \"Chunk Overlap\",\n                \"info\": \"The amount of character overlap between chunks.\",\n                \"field_type\": \"int\",\n                \"value\": 200,\n            },\n            \"recursive\": {\n                \"display_name\": \"Recursive\",\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        inputs: list[Text],\n        separators: Optional[list[str]] = [\" \"],\n        chunk_size: Optional[int] = 1000,\n        chunk_overlap: Optional[int] = 200,\n        recursive: bool = False,\n    ) -> list[Record]:\n        if separators is None:\n            separators = []\n        separators = [unescape_string(x) for x in separators]\n\n        # Make sure chunk_size and chunk_overlap are ints\n        if isinstance(chunk_size, str):\n            chunk_size = int(chunk_size)\n        if isinstance(chunk_overlap, str):\n            chunk_overlap = int(chunk_overlap)\n        splitter: Optional[Union[CharacterTextSplitter, RecursiveCharacterTextSplitter]] = None\n        if recursive:\n            splitter = RecursiveCharacterTextSplitter(\n                separators=separators,\n                chunk_size=chunk_size,\n                chunk_overlap=chunk_overlap,\n            )\n\n        else:\n            splitter = CharacterTextSplitter(\n                separator=separators[0],\n                chunk_size=chunk_size,\n                chunk_overlap=chunk_overlap,\n            )\n\n        documents = []\n        for _input in inputs:\n            if isinstance(_input, Record):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(Document(page_content=_input))\n\n        records = self.to_records(splitter.split_documents(documents))\n        self.status = records\n        return records\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"recursive":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"recursive","display_name":"Recursive","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"separators":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":[" "],"fileTypes":[],"file_path":"","password":false,"name":"separators","display_name":"Separators","advanced":false,"dynamic":false,"info":"The characters to split on. Defaults to [\" \"].","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Split text into chunks of a specified length.","base_classes":["Record"],"display_name":"Split Text","documentation":"","custom_fields":{"inputs":null,"separators":null,"chunk_size":null,"chunk_overlap":null,"recursive":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"SplitText-aRYow"},"selected":false,"width":384,"height":615},{"id":"AstraDBSearch-XNsqI","type":"genericNode","position":{"x":1416.9329896291501,"y":895.3661849816322},"data":{"type":"AstraDBSearch","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"Embedding to use","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input Value","advanced":false,"dynamic":false,"info":"Input value to search","load_from_db":false,"title_case":false,"input_types":["Text"]},"api_endpoint":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"api_endpoint","display_name":"API Endpoint","advanced":false,"dynamic":false,"info":"API endpoint URL for the Astra DB service.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"https://bb20db55-ad46-4cc0-bde5-349ac80533a3-us-east1.apps.astra.datastax.com"},"batch_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"batch_size","display_name":"Batch Size","advanced":true,"dynamic":false,"info":"Optional number of records to process in a single batch.","load_from_db":false,"title_case":false},"bulk_delete_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_delete_concurrency","display_name":"Bulk Delete Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk delete operations.","load_from_db":false,"title_case":false},"bulk_insert_batch_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_insert_batch_concurrency","display_name":"Bulk Insert Batch Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations.","load_from_db":false,"title_case":false},"bulk_insert_overwrite_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_insert_overwrite_concurrency","display_name":"Bulk Insert Overwrite Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations that overwrite existing records.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional\n\nfrom langflow.components.vectorstores.AstraDB import AstraDBVectorStoreComponent\nfrom langflow.components.vectorstores.base.model import LCVectorStoreComponent\nfrom langflow.field_typing import Embeddings, Text\nfrom langflow.schema import Record\n\n\nclass AstraDBSearchComponent(LCVectorStoreComponent):\n    display_name = \"Astra DB Search\"\n    description = \"Searches an existing Astra DB Vector Store.\"\n    icon = \"AstraDB\"\n    field_order = [\"token\", \"api_endpoint\", \"collection_name\", \"input_value\", \"embedding\"]\n\n    def build_config(self):\n        return {\n            \"search_type\": {\n                \"display_name\": \"Search Type\",\n                \"options\": [\"Similarity\", \"MMR\"],\n            },\n            \"input_value\": {\n                \"display_name\": \"Input Value\",\n                \"info\": \"Input value to search\",\n            },\n            \"embedding\": {\"display_name\": \"Embedding\", \"info\": \"Embedding to use\"},\n            \"collection_name\": {\n                \"display_name\": \"Collection Name\",\n                \"info\": \"The name of the collection within Astra DB where the vectors will be stored.\",\n            },\n            \"token\": {\n                \"display_name\": \"Token\",\n                \"info\": \"Authentication token for accessing Astra DB.\",\n                \"password\": True,\n            },\n            \"api_endpoint\": {\n                \"display_name\": \"API Endpoint\",\n                \"info\": \"API endpoint URL for the Astra DB service.\",\n            },\n            \"namespace\": {\n                \"display_name\": \"Namespace\",\n                \"info\": \"Optional namespace within Astra DB to use for the collection.\",\n                \"advanced\": True,\n            },\n            \"metric\": {\n                \"display_name\": \"Metric\",\n                \"info\": \"Optional distance metric for vector comparisons in the vector store.\",\n                \"advanced\": True,\n            },\n            \"batch_size\": {\n                \"display_name\": \"Batch Size\",\n                \"info\": \"Optional number of records to process in a single batch.\",\n                \"advanced\": True,\n            },\n            \"bulk_insert_batch_concurrency\": {\n                \"display_name\": \"Bulk Insert Batch Concurrency\",\n                \"info\": \"Optional concurrency level for bulk insert operations.\",\n                \"advanced\": True,\n            },\n            \"bulk_insert_overwrite_concurrency\": {\n                \"display_name\": \"Bulk Insert Overwrite Concurrency\",\n                \"info\": \"Optional concurrency level for bulk insert operations that overwrite existing records.\",\n                \"advanced\": True,\n            },\n            \"bulk_delete_concurrency\": {\n                \"display_name\": \"Bulk Delete Concurrency\",\n                \"info\": \"Optional concurrency level for bulk delete operations.\",\n                \"advanced\": True,\n            },\n            \"setup_mode\": {\n                \"display_name\": \"Setup Mode\",\n                \"info\": \"Configuration mode for setting up the vector store, with options like “Sync”, “Async”, or “Off”.\",\n                \"options\": [\"Sync\", \"Async\", \"Off\"],\n                \"advanced\": True,\n            },\n            \"pre_delete_collection\": {\n                \"display_name\": \"Pre Delete Collection\",\n                \"info\": \"Boolean flag to determine whether to delete the collection before creating a new one.\",\n                \"advanced\": True,\n            },\n            \"metadata_indexing_include\": {\n                \"display_name\": \"Metadata Indexing Include\",\n                \"info\": \"Optional list of metadata fields to include in the indexing.\",\n                \"advanced\": True,\n            },\n            \"metadata_indexing_exclude\": {\n                \"display_name\": \"Metadata Indexing Exclude\",\n                \"info\": \"Optional list of metadata fields to exclude from the indexing.\",\n                \"advanced\": True,\n            },\n            \"collection_indexing_policy\": {\n                \"display_name\": \"Collection Indexing Policy\",\n                \"info\": \"Optional dictionary defining the indexing policy for the collection.\",\n                \"advanced\": True,\n            },\n            \"number_of_results\": {\n                \"display_name\": \"Number of Results\",\n                \"info\": \"Number of results to return.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        embedding: Embeddings,\n        collection_name: str,\n        input_value: Text,\n        token: str,\n        api_endpoint: str,\n        search_type: str = \"Similarity\",\n        number_of_results: int = 4,\n        namespace: Optional[str] = None,\n        metric: Optional[str] = None,\n        batch_size: Optional[int] = None,\n        bulk_insert_batch_concurrency: Optional[int] = None,\n        bulk_insert_overwrite_concurrency: Optional[int] = None,\n        bulk_delete_concurrency: Optional[int] = None,\n        setup_mode: str = \"Sync\",\n        pre_delete_collection: bool = False,\n        metadata_indexing_include: Optional[List[str]] = None,\n        metadata_indexing_exclude: Optional[List[str]] = None,\n        collection_indexing_policy: Optional[dict] = None,\n    ) -> List[Record]:\n        vector_store = AstraDBVectorStoreComponent().build(\n            embedding=embedding,\n            collection_name=collection_name,\n            token=token,\n            api_endpoint=api_endpoint,\n            namespace=namespace,\n            metric=metric,\n            batch_size=batch_size,\n            bulk_insert_batch_concurrency=bulk_insert_batch_concurrency,\n            bulk_insert_overwrite_concurrency=bulk_insert_overwrite_concurrency,\n            bulk_delete_concurrency=bulk_delete_concurrency,\n            setup_mode=setup_mode,\n            pre_delete_collection=pre_delete_collection,\n            metadata_indexing_include=metadata_indexing_include,\n            metadata_indexing_exclude=metadata_indexing_exclude,\n            collection_indexing_policy=collection_indexing_policy,\n        )\n        try:\n            return self.search_with_vector_store(input_value, search_type, vector_store, k=number_of_results)\n        except KeyError as e:\n            if \"content\" in str(e):\n                raise ValueError(\n                    \"You should ingest data through Langflow (or LangChain) to query it in Langflow. Your collection does not contain a field name 'content'.\"\n                )\n            else:\n                raise e\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_indexing_policy":{"type":"dict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_indexing_policy","display_name":"Collection Indexing Policy","advanced":true,"dynamic":false,"info":"Optional dictionary defining the indexing policy for the collection.","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"The name of the collection within Astra DB where the vectors will be stored.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"pdf"},"metadata_indexing_exclude":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata_indexing_exclude","display_name":"Metadata Indexing Exclude","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to exclude from the indexing.","load_from_db":false,"title_case":false,"input_types":["Text"]},"metadata_indexing_include":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata_indexing_include","display_name":"Metadata Indexing Include","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to include in the indexing.","load_from_db":false,"title_case":false,"input_types":["Text"]},"metric":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metric","display_name":"Metric","advanced":true,"dynamic":false,"info":"Optional distance metric for vector comparisons in the vector store.","load_from_db":false,"title_case":false,"input_types":["Text"]},"namespace":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"namespace","display_name":"Namespace","advanced":true,"dynamic":false,"info":"Optional namespace within Astra DB to use for the collection.","load_from_db":false,"title_case":false,"input_types":["Text"]},"number_of_results":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":4,"fileTypes":[],"file_path":"","password":false,"name":"number_of_results","display_name":"Number of Results","advanced":true,"dynamic":false,"info":"Number of results to return.","load_from_db":false,"title_case":false},"pre_delete_collection":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"pre_delete_collection","display_name":"Pre Delete Collection","advanced":true,"dynamic":false,"info":"Boolean flag to determine whether to delete the collection before creating a new one.","load_from_db":false,"title_case":false},"search_type":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Similarity","fileTypes":[],"file_path":"","password":false,"options":["Similarity","MMR"],"name":"search_type","display_name":"Search Type","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"setup_mode":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Sync","fileTypes":[],"file_path":"","password":false,"options":["Sync","Async","Off"],"name":"setup_mode","display_name":"Setup Mode","advanced":true,"dynamic":false,"info":"Configuration mode for setting up the vector store, with options like “Sync”, “Async”, or “Off”.","load_from_db":false,"title_case":false,"input_types":["Text"]},"token":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"token","display_name":"Token","advanced":false,"dynamic":false,"info":"Authentication token for accessing Astra DB.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"AstraCS:vAMZkfwNjndvIYjaRcexnWpQ:4e52e6a1e8f83086c8108f248dfc58295345384a2cddcb734690aa433b88a98f"},"_type":"CustomComponent"},"description":"Searches an existing Astra DB Vector Store.","icon":"AstraDB","base_classes":["Record"],"display_name":"Astra DB Search","documentation":"","custom_fields":{"embedding":null,"collection_name":null,"input_value":null,"token":null,"api_endpoint":null,"search_type":null,"number_of_results":null,"namespace":null,"metric":null,"batch_size":null,"bulk_insert_batch_concurrency":null,"bulk_insert_overwrite_concurrency":null,"bulk_delete_concurrency":null,"setup_mode":null,"pre_delete_collection":null,"metadata_indexing_include":null,"metadata_indexing_exclude":null,"collection_indexing_policy":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":["token","api_endpoint","collection_name","input_value","embedding"],"beta":false},"id":"AstraDBSearch-XNsqI"},"selected":false,"width":384,"height":713,"dragging":false,"positionAbsolute":{"x":1416.9329896291501,"y":895.3661849816322}},{"id":"URL-S3xy4","type":"genericNode","position":{"x":-385.08618697124393,"y":1551.4145137259645},"data":{"type":"URL","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Any, Dict\n\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\n\nfrom langflow.interface.custom.custom_component import CustomComponent\nfrom langflow.schema import Record\n\n\nclass URLComponent(CustomComponent):\n    display_name = \"URL\"\n    description = \"Fetch content from one or more URLs.\"\n    icon = \"layout-template\"\n\n    def build_config(self) -> Dict[str, Any]:\n        return {\n            \"urls\": {\"display_name\": \"URL\"},\n        }\n\n    def build(\n        self,\n        urls: list[str],\n    ) -> list[Record]:\n        loader = WebBaseLoader(web_paths=urls)\n        docs = loader.load()\n        records = self.to_records(docs)\n        self.status = records\n        return records\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"urls":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"urls","display_name":"URL","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":["https://focs.tarc.edu.my/programmes/foundation","https://focs.tarc.edu.my/about-us","https://focs.tarc.edu.my/home","https://focs.tarc.edu.my/people_1/faculty-staff","https://focs.tarc.edu.my/programmes/postgraduate","https://focs.tarc.edu.my/facilities","https://focs.tarc.edu.my/programmes/diploma/diploma-in-computer-science-dcs","https://focs.tarc.edu.my/programmes/diploma/diploma-in-information-technology-dft","https://focs.tarc.edu.my/programmes/diploma/diploma-in-software-engineering-dsf","https://focs.tarc.edu.my/programmes/diploma"]},"_type":"CustomComponent"},"description":"Fetch content from one or more URLs.","icon":"layout-template","base_classes":["Record"],"display_name":"URL","documentation":"","custom_fields":{"urls":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"URL-S3xy4"},"selected":false,"width":384,"height":731,"dragging":false,"positionAbsolute":{"x":-385.08618697124393,"y":1551.4145137259645}}],"edges":[{"source":"TextInput-zvrMz","target":"ChatInput-JY2A0","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-zvrMzœ}","targetHandle":"{œfieldNameœ:œsender_nameœ,œidœ:œChatInput-JY2A0œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","id":"reactflow__edge-TextInput-zvrMz{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-zvrMzœ}-ChatInput-JY2A0{œfieldNameœ:œsender_nameœ,œidœ:œChatInput-JY2A0œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"sender_name","id":"ChatInput-JY2A0","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextInput","id":"TextInput-zvrMz"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","selected":false},{"source":"TextInput-zvrMz","target":"MemoryComponent-k8Jsz","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-zvrMzœ}","targetHandle":"{œfieldNameœ:œsession_idœ,œidœ:œMemoryComponent-k8Jszœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","id":"reactflow__edge-TextInput-zvrMz{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-zvrMzœ}-MemoryComponent-k8Jsz{œfieldNameœ:œsession_idœ,œidœ:œMemoryComponent-k8Jszœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"session_id","id":"MemoryComponent-k8Jsz","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextInput","id":"TextInput-zvrMz"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","selected":false},{"source":"Prompt-qT5rm","target":"OllamaModel-Sso5e","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-qT5rmœ}","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOllamaModel-Sso5eœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","id":"reactflow__edge-Prompt-qT5rm{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-qT5rmœ}-OllamaModel-Sso5e{œfieldNameœ:œinput_valueœ,œidœ:œOllamaModel-Sso5eœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"OllamaModel-Sso5e","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"Prompt","id":"Prompt-qT5rm"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","selected":false},{"source":"OllamaModel-Sso5e","target":"ChatOutput-2WjKE","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOllamaModelœ,œidœ:œOllamaModel-Sso5eœ}","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-2WjKEœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","id":"reactflow__edge-OllamaModel-Sso5e{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOllamaModelœ,œidœ:œOllamaModel-Sso5eœ}-ChatOutput-2WjKE{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-2WjKEœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-2WjKE","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"OllamaModel","id":"OllamaModel-Sso5e"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","selected":false},{"source":"OllamaEmbeddings-mv0aG","target":"AstraDB-wA82a","sourceHandle":"{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-mv0aGœ}","targetHandle":"{œfieldNameœ:œembeddingœ,œidœ:œAstraDB-wA82aœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}","id":"reactflow__edge-OllamaEmbeddings-mv0aG{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-mv0aGœ}-AstraDB-wA82a{œfieldNameœ:œembeddingœ,œidœ:œAstraDB-wA82aœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}","data":{"targetHandle":{"fieldName":"embedding","id":"AstraDB-wA82a","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"OllamaEmbeddings","id":"OllamaEmbeddings-mv0aG"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","selected":false},{"source":"File-NZc5f","target":"SplitText-aRYow","sourceHandle":"{œbaseClassesœ:[œRecordœ],œdataTypeœ:œFileœ,œidœ:œFile-NZc5fœ}","targetHandle":"{œfieldNameœ:œinputsœ,œidœ:œSplitText-aRYowœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}","id":"reactflow__edge-File-NZc5f{œbaseClassesœ:[œRecordœ],œdataTypeœ:œFileœ,œidœ:œFile-NZc5fœ}-SplitText-aRYow{œfieldNameœ:œinputsœ,œidœ:œSplitText-aRYowœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"inputs","id":"SplitText-aRYow","inputTypes":["Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Record"],"dataType":"File","id":"File-NZc5f"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","selected":false},{"source":"SplitText-aRYow","target":"AstraDB-wA82a","sourceHandle":"{œbaseClassesœ:[œRecordœ],œdataTypeœ:œSplitTextœ,œidœ:œSplitText-aRYowœ}","targetHandle":"{œfieldNameœ:œinputsœ,œidœ:œAstraDB-wA82aœ,œinputTypesœ:null,œtypeœ:œRecordœ}","id":"reactflow__edge-SplitText-aRYow{œbaseClassesœ:[œRecordœ],œdataTypeœ:œSplitTextœ,œidœ:œSplitText-aRYowœ}-AstraDB-wA82a{œfieldNameœ:œinputsœ,œidœ:œAstraDB-wA82aœ,œinputTypesœ:null,œtypeœ:œRecordœ}","data":{"targetHandle":{"fieldName":"inputs","id":"AstraDB-wA82a","inputTypes":null,"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"SplitText","id":"SplitText-aRYow"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","selected":false},{"source":"ChatInput-JY2A0","target":"AstraDBSearch-XNsqI","sourceHandle":"{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-JY2A0œ}","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œAstraDBSearch-XNsqIœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","id":"reactflow__edge-ChatInput-JY2A0{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-JY2A0œ}-AstraDBSearch-XNsqI{œfieldNameœ:œinput_valueœ,œidœ:œAstraDBSearch-XNsqIœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"AstraDBSearch-XNsqI","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","Record","str","Text"],"dataType":"ChatInput","id":"ChatInput-JY2A0"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","selected":false},{"source":"OllamaEmbeddings-mv0aG","target":"AstraDBSearch-XNsqI","sourceHandle":"{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-mv0aGœ}","targetHandle":"{œfieldNameœ:œembeddingœ,œidœ:œAstraDBSearch-XNsqIœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}","id":"reactflow__edge-OllamaEmbeddings-mv0aG{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-mv0aGœ}-AstraDBSearch-XNsqI{œfieldNameœ:œembeddingœ,œidœ:œAstraDBSearch-XNsqIœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}","data":{"targetHandle":{"fieldName":"embedding","id":"AstraDBSearch-XNsqI","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"OllamaEmbeddings","id":"OllamaEmbeddings-mv0aG"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","selected":false}],"viewport":{"x":164.73177870187442,"y":198.00433793455022,"zoom":0.5000000000000024}},"description":"Catalyzing Business Growth through Conversational AI.","name":"Fyp_Bot","last_tested_version":"1.0.0a32","is_component":false}